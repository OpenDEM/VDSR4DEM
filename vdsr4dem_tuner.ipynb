{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "vdsr4dem_tuner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idupnGQ-I-UC"
      },
      "source": [
        "VDSR for DEM processing - Tuner\n",
        "====================================\n",
        "**Using the [Keras Tuner](https://www.tensorflow.org/tutorials/keras/keras_tuner) to pick the optimal set of hyperparameters for a Very Deep Super Resolution (VDSR) CNN.**\n",
        "\n",
        "More about machine learning techniques for improved resolution of Digital Elevation Models:  [Super-resolution](https://opendem.info/opendemsearcher.html)\n",
        "\n",
        "The original VDSR implementation was done by George Seif [GitHub](https://github.com/GeorgeSeif/VDSR-Keras).\n",
        "\n",
        "This Notebook is running on Google Colab with data storage on Google Drive. Of course this could be adapted to local resources.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXvhPyws9-T7",
        "outputId": "d292cade-3bf6-4682-eb41-da257fc50fb3"
      },
      "source": [
        "import os\n",
        "# connect with google drive  \n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_AGZx2bNS8g"
      },
      "source": [
        "Get rasterio for GeoTiff processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxoYac2yx9lS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "418d38fb-5450-4b3b-f406-9c329701ae3e"
      },
      "source": [
        "!pip install rasterio"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPMTTGgtZHYd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68500181-54e7-487a-afc8-af8f628ea3cc"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from tensorflow.python.data.experimental import AUTOTUNE\n",
        "from rasterio.plot import reshape_as_image, reshape_as_raster, show\n",
        "import re\n",
        "\n",
        "# adapt your paths\n",
        "HR_PATH_TRAIN = \"/content/drive/My Drive/vdsr4dem/hr_train\"\n",
        "LR_PATH_TRAIN = \"/content/drive/My Drive/vdsr4dem/lr_train\"\n",
        "HR_PATH_VAL = \"/content/drive/My Drive/sr_images/hr_valid\"\n",
        "LR_PATH_VAL = \"/content/drive/My Drive/sr_images/lr_valid\"\n",
        "\n",
        "\n",
        "# maximal and minimal values of the whole trainings dataset\n",
        "ds_max = 3150\n",
        "ds_min = 170\n",
        "\n",
        "# use human sorting to avoid problems with the order of the files for training and validation\n",
        "def atoi(text):\n",
        "    return int(text) if text.isdigit() else text\n",
        "\n",
        "def natural_keys(text):\n",
        "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]\n",
        "\n",
        "def _images_dataset(image_files):    \n",
        "    listAll = []\n",
        "    for img in image_files:\n",
        "        with rasterio.open(img) as src:\n",
        "            array = src.read(\n",
        "                out_shape=(\n",
        "                    src.count,\n",
        "                    int(src.height),\n",
        "                    int(src.width)\n",
        "                )\n",
        "            )\n",
        "            array = reshape_as_image(array)            \n",
        "            lr = (array - ds_min) / (ds_max - ds_min)\n",
        "            listAll.append(lr)        \n",
        "    ds = tf.data.Dataset.from_tensor_slices(listAll)\n",
        "    #print(ds)\n",
        "    return ds\n",
        "\n",
        "def _get_dataset(path, num_images):\n",
        "    file_names = [f\"{path}/{x}\" for x in os.listdir(path) if x.find(\".tif\") != -1]\n",
        "    if num_images is not None:\n",
        "        file_names = file_names[:num_images]\n",
        "    print(\"--->\", len(file_names))\n",
        "    file_names.sort(key=natural_keys)\n",
        "    print(file_names)\n",
        "    ds = _images_dataset(file_names)    \n",
        "    return ds\n",
        "\n",
        "\n",
        "def dataset(batch_size=16, repeat_count=None, random_transform=True, use_set=\"train\", num_images=None):\n",
        "    print(num_images)\n",
        "    if use_set == \"train\":\n",
        "        print('LR_PATH_TRAIN')\n",
        "        lr_ds = _get_dataset(LR_PATH_TRAIN, num_images)\n",
        "        print('HR_PATH_TRAIN')\n",
        "        hr_ds = _get_dataset(HR_PATH_TRAIN, num_images)\n",
        "    elif use_set == \"val\":\n",
        "        print('LR_PATH_VAL')\n",
        "        lr_ds = _get_dataset(LR_PATH_VAL, num_images)\n",
        "        print('HR_PATH_VAL')\n",
        "        hr_ds = _get_dataset(HR_PATH_VAL, num_images)\n",
        "    else:\n",
        "        return None\n",
        "    \n",
        "    ds = tf.data.Dataset.zip((lr_ds, hr_ds))\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # To avoid problems with the order of the files always set num_images to the real number of images in the folder!\n",
        "    train_ds = dataset(batch_size=16, use_set=\"train\", num_images=101)\n",
        "    val_ds = dataset(batch_size=1, use_set=\"val\", num_images=31)\n",
        "    print(\"done all\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vy4MwNTwlcjR"
      },
      "source": [
        "Get the Keras Tuner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piZkmDQHB3Hy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ba64a86-c279-4e89-90c6-a0ec057a9881"
      },
      "source": [
        "!pip install keras-tuner"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g80C4ZEqvAI"
      },
      "source": [
        "# Step 1\r\n",
        "Pick the optimal hyperparaters:\r\n",
        "\r\n",
        "\r\n",
        "*   filter kernel size\r\n",
        "*   filters\r\n",
        "*   learning rate   \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIGbw7lgHfsQ"
      },
      "source": [
        "from kerastuner import HyperModel\r\n",
        "from keras.models import Sequential, Model\r\n",
        "from keras import Sequential\r\n",
        "from keras.layers import Conv2D\r\n",
        "from keras.models import Sequential, Model\r\n",
        "from keras.layers import Dense, Activation, Input, add\r\n",
        "from keras import optimizers\r\n",
        "from keras import losses\r\n",
        "from keras.optimizers import SGD, Adam\r\n",
        "\r\n",
        "class RegressionHyperModel(HyperModel):\r\n",
        "    def __init__(self, input_shape):\r\n",
        "        self.input_shape = input_shape        \r\n",
        "\r\n",
        "    def build(self, hp):\r\n",
        "        model = keras.Sequential()\r\n",
        "\r\n",
        "        filter = hp.Choice('filter', values = [4,8,16,32,64]);\r\n",
        "        kernel = hp.Choice('kernel', values = [5,9,15,21]);\r\n",
        "\r\n",
        "\r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters= filter,\r\n",
        "                kernel_size= kernel,\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',\r\n",
        "                activation='relu',\r\n",
        "                input_shape=(300, 300, 1)\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters= filter,\r\n",
        "                kernel_size= kernel,\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',\r\n",
        "                activation='relu',\r\n",
        "                input_shape=model.output_shape\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters= filter,\r\n",
        "                kernel_size= kernel,\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',\r\n",
        "                activation='relu',\r\n",
        "                input_shape=model.output_shape\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters= filter,\r\n",
        "                kernel_size= kernel,\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',\r\n",
        "                activation='relu',\r\n",
        "                input_shape=model.output_shape\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters= filter,\r\n",
        "                kernel_size= kernel,\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',\r\n",
        "                activation='relu',\r\n",
        "                input_shape=model.output_shape\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters= filter,\r\n",
        "                kernel_size= kernel,\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',\r\n",
        "                activation='relu',\r\n",
        "                input_shape=model.output_shape\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters= filter,\r\n",
        "                kernel_size= kernel,\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',\r\n",
        "                activation='relu',\r\n",
        "                input_shape=model.output_shape\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters= filter,\r\n",
        "                kernel_size= kernel,\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',\r\n",
        "                activation='relu',\r\n",
        "                input_shape=model.output_shape\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters= filter,\r\n",
        "                kernel_size= kernel,\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',\r\n",
        "                activation='relu',\r\n",
        "                input_shape=model.output_shape\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters= filter,\r\n",
        "                kernel_size= kernel,\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',\r\n",
        "                activation='relu',\r\n",
        "                input_shape=model.output_shape\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters= filter,\r\n",
        "                kernel_size= kernel,\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',\r\n",
        "                activation='relu',\r\n",
        "                input_shape=model.output_shape\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters= filter,\r\n",
        "                kernel_size= kernel,\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',\r\n",
        "                activation='relu',\r\n",
        "                input_shape=model.output_shape\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters= filter,\r\n",
        "                kernel_size= kernel,\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',\r\n",
        "                activation='relu',\r\n",
        "                input_shape=model.output_shape\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters= filter,\r\n",
        "                kernel_size= kernel,\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',\r\n",
        "                activation='relu',\r\n",
        "                input_shape=model.output_shape\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters= filter,\r\n",
        "                kernel_size= kernel,\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',\r\n",
        "                activation='relu',\r\n",
        "                input_shape=model.output_shape\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters= filter,\r\n",
        "                kernel_size= kernel,\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',\r\n",
        "                activation='relu',\r\n",
        "                input_shape=model.output_shape\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters= filter,\r\n",
        "                kernel_size= kernel,\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',\r\n",
        "                activation='relu',\r\n",
        "                input_shape=model.output_shape\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters= filter,\r\n",
        "                kernel_size= kernel,\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',\r\n",
        "                activation='relu',\r\n",
        "                input_shape=model.output_shape\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters= filter,\r\n",
        "                kernel_size= kernel,\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',\r\n",
        "                activation='relu',\r\n",
        "                input_shape=model.output_shape\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters= filter,\r\n",
        "                kernel_size= kernel,\r\n",
        "                activation='relu',\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',             \r\n",
        "                input_shape=model.output_shape\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.compile(\r\n",
        "            optimizer=keras.optimizers.Adam(\r\n",
        "                hp.Choice('learning_rate',\r\n",
        "                      values=[0.001, 0.0001, 0.00001, 0.000001])),\r\n",
        "            loss='mse',\r\n",
        "            metrics=['mse']\r\n",
        "        )\r\n",
        "        return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZTU9BvkMMwE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a06480d-fe51-4d4c-f8b5-dbe2cc18d968"
      },
      "source": [
        "from tensorflow import keras\r\n",
        "from kerastuner.tuners import RandomSearch\r\n",
        "\r\n",
        "hypermodel = RegressionHyperModel(input_shape=(300, 300, 1))\r\n",
        "\r\n",
        "tuner_rs = RandomSearch(\r\n",
        " hypermodel,\r\n",
        " objective='mse',\r\n",
        " seed=42,\r\n",
        " max_trials=100,\r\n",
        " # adapt path\r\n",
        " directory='/content/drive/My Drive/tunerdirectory12',\r\n",
        " executions_per_trial=5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project /content/drive/My Drive/tunerdirectory12/untitled_project/oracle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZfBpmtZZaSM",
        "outputId": "8e53c5de-58ae-49f4-8ead-911c51c0355a"
      },
      "source": [
        "tuner_rs.search_space_summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 3\n",
            "filter (Choice)\n",
            "{'default': 4, 'conditions': [], 'values': [4, 8, 16, 32, 64], 'ordered': True}\n",
            "kernel (Choice)\n",
            "{'default': 5, 'conditions': [], 'values': [5, 9, 15, 21], 'ordered': True}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.001, 'conditions': [], 'values': [0.001, 0.0001, 1e-05, 1e-06], 'ordered': True}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zEFZYUGZ3B_"
      },
      "source": [
        "N_EPOCH_SEARCH = 50\r\n",
        "\r\n",
        "tuner_rs.search(train_ds, validation_data=val_ds, epochs=N_EPOCH_SEARCH)\r\n",
        "\r\n",
        "tuner_rs.results_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSNVml29lq_X"
      },
      "source": [
        "# Step 2\r\n",
        "Use a loop (1-30) to pick the optimum number of CNN layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fivvuLDVwht_"
      },
      "source": [
        "from kerastuner import HyperModel\r\n",
        "from keras.models import Sequential, Model\r\n",
        "from keras import Sequential\r\n",
        "from keras.layers import Conv2D\r\n",
        "from keras.models import Sequential, Model\r\n",
        "from keras.layers import Dense, Activation, Input, add\r\n",
        "from keras import optimizers\r\n",
        "from keras import losses\r\n",
        "from keras.optimizers import SGD, Adam\r\n",
        "\r\n",
        "class RegressionHyperModel(HyperModel):\r\n",
        "    def __init__(self, input_shape):\r\n",
        "        self.input_shape = input_shape        \r\n",
        "\r\n",
        "    def build(self, hp):\r\n",
        "        model = keras.Sequential()\r\n",
        "        \r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters=32,\r\n",
        "                kernel_size=9,\r\n",
        "                activation='relu',\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',             \r\n",
        "                input_shape=(300, 300, 1)\r\n",
        "            )\r\n",
        "        )\r\n",
        "\r\n",
        "        for i in range(hp.Int('n_layers', 1, 30)):  # adding variation of layers.\r\n",
        "            model.add(\r\n",
        "                Conv2D(\r\n",
        "                    filters=32,\r\n",
        "                    kernel_size=9,\r\n",
        "                    activation='relu',\r\n",
        "                    padding='same',\r\n",
        "                    kernel_initializer='he_normal',             \r\n",
        "                    input_shape=(300, 300, 1)\r\n",
        "                )\r\n",
        "            )\r\n",
        "\r\n",
        "        \r\n",
        "        model.add(\r\n",
        "            Conv2D(\r\n",
        "                filters=1,\r\n",
        "                kernel_size=9,\r\n",
        "                activation='relu',\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',             \r\n",
        "                input_shape=model.output_shape\r\n",
        "            )\r\n",
        "        )\r\n",
        "        adam = Adam(lr=0.0001)\r\n",
        "        model.compile(\r\n",
        "            adam,\r\n",
        "            loss='mse',\r\n",
        "            metrics=['mse']\r\n",
        "        )\r\n",
        "        return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v7JheizOWBi"
      },
      "source": [
        "from tensorflow import keras\r\n",
        "from kerastuner.tuners import RandomSearch\r\n",
        "\r\n",
        "hypermodel = RegressionHyperModel(input_shape=(300, 300, 1))\r\n",
        "\r\n",
        "tuner_rs = RandomSearch(\r\n",
        " hypermodel,\r\n",
        " objective='mse',\r\n",
        " seed=42,\r\n",
        " max_trials=100,\r\n",
        " # adapt path\r\n",
        " directory='/content/drive/My Drive/tunerdirectory14',\r\n",
        " executions_per_trial=5)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ziRyPVOOa9n",
        "outputId": "0906d93b-ef90-4538-9deb-a8b983e007a6"
      },
      "source": [
        "tuner_rs.search_space_summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 1\n",
            "n_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 30, 'step': 1, 'sampling': None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd5nqV2VOfSM"
      },
      "source": [
        "N_EPOCH_SEARCH = 50\r\n",
        "\r\n",
        "tuner_rs.search(train_ds, validation_data=val_ds, epochs=N_EPOCH_SEARCH)\r\n",
        "\r\n",
        "tuner_rs.results_summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
